{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5db0c4",
   "metadata": {},
   "source": [
    "# Learn PyTorch from https://www.learnpytorch.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8c58b158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ccf3f",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "###  Creating tensors\n",
    "\n",
    "PyTorch tensors are created using `torch.Tensor()` = https://docs.pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c8a75300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "# scalar \n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f074b493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1009972d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get tensor back as python int \n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "350ec088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 7])\n"
     ]
    }
   ],
   "source": [
    "# Vector\n",
    "\n",
    "vector = torch.tensor([7, 7])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c788a68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0880622d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "03b129bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "\n",
    "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "28222db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e0a93f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "39a34d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b3c7cd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]])\n",
    "\n",
    "TENSOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "871ee980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a6468a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5875f5d",
   "metadata": {},
   "source": [
    "## Random Tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they \n",
    "start with tensors full of random numbers and then adjust those \n",
    "random numbers to better represent the data.\n",
    "\n",
    "`Start with the random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n",
    "\n",
    "\n",
    "Torch random tensors - https://pytorch.org/docs/stable/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2ebbded7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
       "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
       "        [0.2696, 0.4414, 0.2969, 0.8317]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a radmon tensors of size (3,4)\n",
    "\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7d47d604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensors with similar shape to an image tensor\n",
    "\n",
    "random_image_size_tensor = torch.rand(size=(3, 224, 224)) # (color channels (RGB),height, width)\n",
    "random_image_size_tensor.shape,random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39f28ea",
   "metadata": {},
   "source": [
    "### Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d66007ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensors of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e1630b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensors of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5dcbaedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf678a4",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6181724f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange() \n",
    "# torch.range() is deprecated\n",
    "\n",
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b925e60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e61b1b",
   "metadata": {},
   "source": [
    "### Tensors Data Types\n",
    "**NOTE** Tensors data types is one of the 3 big errors you'll run into with PyTorch & deep learning.\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device \n",
    "\n",
    "Perceptron in computing - https://en.wikipedia.org/wiki/Precision_(computer_science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cc12fa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensors\n",
    "\n",
    "float_32_tensor =  torch.tensor([3.0, 6.0, 9.0], dtype=None, # What datatype is the tensors (eg float32 or float64 or float16)\n",
    "                                                device=None,  # Which devices is your tensors on \n",
    "                                                requires_grad=False) # Whether or not to track gradients with this tensors operations\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0a5419cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c2dc3f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "78cf3ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1c4e3251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4b4ae224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df441d",
   "metadata": {},
   "source": [
    "### Getting information from tensors ( tensors attributes)\n",
    "\n",
    "1. Tensors not right datatype - to do get datatype from a tensor use `torch.dtype`\n",
    "2. Tensors not right shape - to do get shape from a tensor use `torch.shape`\n",
    "3. Tensors not on the right device - to do get device from a tensor use `torch.device`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9638c5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5745, 0.9200, 0.3230, 0.8613],\n",
       "        [0.0919, 0.3102, 0.9536, 0.6002],\n",
       "        [0.0351, 0.6826, 0.3743, 0.5220]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ca49cad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5745, 0.9200, 0.3230, 0.8613],\n",
      "        [0.0919, 0.3102, 0.9536, 0.6002],\n",
      "        [0.0351, 0.6826, 0.3743, 0.5220]])\n",
      "Data type of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about dtypes\n",
    "print(some_tensor)\n",
    "print(f\"Data type of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e260da2",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensors Operations include:\n",
    "\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "364a82f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cd48720d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multipy by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "76e3717b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c2a4f815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substract 10\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "590f7e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out PyTorch in-build functions\n",
    "torch.mul(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c8f3aeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd88eb",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "Two main ways to perform matrix multiplication in Neural Networks and Deep Learning :\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "More information on multiplication: https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
    "\n",
    "There are two main rules that performing matrix multiplication must follow:\n",
    "1. The **inner dimensions must match**:\n",
    "* `(3,2) @ (2,3)` will work\n",
    "* `(3,2) @ (3,2)` will not work\n",
    "* `(2,3) @ (3,2)` will work\n",
    "2. The result matrix has the shape of the **outer dimensions**:\n",
    "* `(2,3) @ (3,2)`-> `(2,2)`\n",
    "* `(3,2) @ (2,3)`-> `(3,3)`\n",
    "\n",
    "To calculate for matrix multiplication, you can use the following website: http://matrixmultiplication.xyz/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c079de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals : tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise operations\n",
    "print(tensor ,\"*\",tensor)\n",
    "print(f\"Equals : {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a120206b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "df377e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication by hand\n",
    "1 * 1 + 2 * 2 + 3  * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9961d49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: user 741 μs, sys: 934 μs, total: 1.68 ms\n",
      "Wall time: 1.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f4feef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 110 μs, sys: 130 μs, total: 240 μs\n",
      "Wall time: 153 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fafd2ee",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning : Shape Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "680b8f25",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[1;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#torch.mm(tensor_A, tensor_B) # torch.mm is the function for matrix multiplication short version of torch.matmul\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for the matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]])\n",
    "\n",
    "#torch.mm(tensor_A, tensor_B) # torch.mm is the function for matrix multiplication short version of torch.matmul\n",
    "torch.matmul(tensor_A, tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7042fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tensor_A.size(), tensor_B.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5652c0",
   "metadata": {},
   "source": [
    "To fix our tensor shape issue, we can manipulate the shape of one of our tensors using a ** transpose**. \n",
    "\n",
    "A **transpose** simply switches the axis or dimensions of a given tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a98bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 10],\n",
       "        [ 8, 11],\n",
       "        [ 9, 12]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e23cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce3ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shapes : tensor_A torch.Size([3, 2]), tensor_B torch.Size([3, 2])\n",
      "New Shapes : tensor_A torch.Size([3, 2]) (same shape as above), tensor_B torch.Size([2, 3])\n",
      "Result Shape : torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dimensions must match\n",
      "Output :\n",
      "\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "Output Shape : torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The matrix mutiplication operation works when tensor_B is transposed\n",
    "\n",
    "print(f\"Original Shapes : tensor_A {tensor_A.shape}, tensor_B {tensor_B.shape}\")\n",
    "print(f\"New Shapes : tensor_A {tensor_A.shape} (same shape as above), tensor_B {tensor_B.T.shape}\")\n",
    "print(f\"Result Shape : {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must match\")\n",
    "print(f\"Output :\\n\")\n",
    "\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output)\n",
    "print(f\"Output Shape : {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4ef80",
   "metadata": {},
   "source": [
    "### Finding the min, max, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13967c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]), torch.int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor \n",
    "x = torch.arange(1, 100, 10) \n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba694b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(1))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7e961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(91), tensor(91))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2bc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(46.), tensor(46.))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean - noted torch.mean() function requires a tensor of float32 datatype to work \n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2d429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(460), tensor(460))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6bc303",
   "metadata": {},
   "source": [
    "## Find the positional of the min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798846d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc954890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the mininum value with argmin() \n",
    "# returns index of target tensor where mininum value occur\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b4984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb610ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the minimum value with argmax()\n",
    "# returns index of target tensor where maximum value occur\n",
    "\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4cfdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28815d1",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* **Reshaping** - reshaps an input tensor to defined shape\n",
    "* **View** - Returns a view of an input tensor of certain shape but keep the same memory as the input\n",
    "* **Stacking** - Combines multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* **Squeeze** - Removes a `1` dimensions from an input tensor\n",
    "* **Unsqueeze** - Adds a `1` dimension to an input tensor\n",
    "* **Permute** - Returns a view of an input tensor with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb7553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensors\n",
    "import torch\n",
    "\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2f19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9]), tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a extra dimension\n",
    "\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped.shape, x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90274f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea515d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changes z changes x ( because a view of a tensor shares the same memory as the original input )\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a154ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensor in top each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # vstack for dim=0 hstack for dim=1\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221550bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Tensor : tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previouse Tensor Shape : torch.Size([1, 9])\n",
      "Squeezed Tensor : tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Squeezed Tensor Shape : torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze - Remove single-dimensional entries from the shape of a tensor\n",
    "\n",
    "print(f\"Previous Tensor : {x_reshaped}\")\n",
    "print(f\"Previouse Tensor Shape : {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimensions from x_reshaped\n",
    "x_squeezed = torch.squeeze(x_reshaped)\n",
    "print(f\"Squeezed Tensor : {x_squeezed}\")\n",
    "print(f\"Squeezed Tensor Shape : {x_squeezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ed362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previouse tensor : tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Shape of previous tensor : torch.Size([9])\n",
      "Unsqueezed tensor : tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Shape of unsqueezed tensor : torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze - Add single-dimension to a target tensor at a specified dim\n",
    "print(f\"Previouse tensor : {x_squeezed}\")\n",
    "print(f\"Shape of previous tensor : {x_squeezed.shape}\")\n",
    "\n",
    "# Add a extra dimension with unsqueeze\n",
    "x_unsqueezed = torch.unsqueeze(x, dim=0)\n",
    "print(f\"Unsqueezed tensor : {x_unsqueezed}\")\n",
    "print(f\"Shape of unsqueezed tensor : {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803cf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "Permuted shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearrange the dimensions of a target tensor in the specified order\n",
    "x_origin = torch.randn(size=(224, 224, 3)) # [height, width, color channel]\n",
    "\n",
    "# Permute the original tensor to rerange the axis or dim order\n",
    "x_permuted = x_origin.permute(2, 0, 1) # shift channel color channel 2->0, height 0->1, width 1->2\n",
    "print(f\"Previous shape: {x_origin.shape}\")\n",
    "print(f\"Permuted shape: {x_permuted.shape}\") # [color channel, height, width] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ded47",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch (Tensor) is similar to indexing with NumPy (Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5fcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the tensor\n",
    "import torch\n",
    "\n",
    "x = torch.arange(start=1, end=10).reshape(1, 3, 3)\n",
    "x, x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7613da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on our new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3bf5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on middle bracket (dim=1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a030226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the most inner bracket (last dimension)\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c778a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use \":\" to select \"all\" a target dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eed401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values 0th and 1st dimension but only index 1 of second dimension\n",
    "\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951b043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 demension but only the 1 index of value of 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77bed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb2e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 9\n",
    "x[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7001c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 3, 6, 9\n",
    "x[:, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ec962",
   "metadata": {},
   "source": [
    "## PyTorch tensors & Numpy arrays\n",
    "NumPy is a popular python library for numerical computing and machine learning.\n",
    "And because of this, PyTorch has functionality to interact with NumPy arrays.\n",
    "\n",
    "* Data in Numpy array, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor, want in Numpy array -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35729ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to torch tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # warning : when converting from numpy -> pytorch reflects numpy's default datatype of float64 unless specified otherwise\n",
    "array, tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be66c90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the values of array, what will this do to tensor?\n",
    "array = array + 1 \n",
    "array, tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f04f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5abe1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happen to numpy_tensor?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5530fc58",
   "metadata": {},
   "source": [
    "## Reproducibility (trying to take out of random)\n",
    "\n",
    "In short how a neural networks learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them better representation of the data -> again -> again -> again`\n",
    "\n",
    "To reduce the randomness in the neural networks and PyTorch comes the concept of **random seed**.\n",
    "\n",
    "Essentially what the random seed does is \"Flavour\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbee728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5308, 0.2336, 0.1312, 0.7669],\n",
      "        [0.4453, 0.3019, 0.3757, 0.6434],\n",
      "        [0.3439, 0.9611, 0.3561, 0.2330]])\n",
      "tensor([[0.0628, 0.1181, 0.9967, 0.1813],\n",
      "        [0.7617, 0.1501, 0.8399, 0.2613],\n",
      "        [0.5917, 0.3409, 0.5343, 0.6632]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb4723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproductible tensors\n",
    "import torch\n",
    "# set the random seed for numpy and torch\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "\n",
    "# Check if the tensors are equal\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea179d",
   "metadata": {},
   "source": [
    "Extra resources for reproducibility:\n",
    "\n",
    "* https://pytorch.org/docs/stable/notes/randomness.html\n",
    "* https://en.wikipedia.org/wiki/Random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a284d",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch object on the GPU (and making faster computations)\n",
    "\n",
    "GPUs = faster computations on numbers, CUDA + NVIDIA hardware + PyTorch work behind the scenes to make everything run faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7c5e0",
   "metadata": {},
   "source": [
    "### Getting a GPU\n",
    "1. Easiest - Use Goolge Colab for a free GPU\n",
    "2. Use your own GPU - takes a little bit of setup and requires GPU\n",
    "3. Use cloud computing - GCP , AWS, Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054832d",
   "metadata": {},
   "source": [
    "### Check for GPU access with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86090dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with PyTorch\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1214594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9050cfb4",
   "metadata": {},
   "source": [
    "For PyTorch since its capable of running compute on the GPU, MPS or CPU , its best practice to setup device agnostic code : \n",
    "https://pytorch.org/docs/stable/notes/cuda.html#best-practices\n",
    "\n",
    "E.g. Run on GPU if available else if MPS run on MPS else run on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e5881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.mps.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b744a18",
   "metadata": {},
   "source": [
    "### Putting tensors ( and models ) on the GPU or MPS or CPU\n",
    "\n",
    "The reason we want our tensors/models on the GPU is because using GPU results is faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "68408565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor device: cpu\n",
      "Tensor: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(\"Tensor device:\", tensor.device)\n",
    "print(\"Tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "62d268ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU if available\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39201cb3",
   "metadata": {},
   "source": [
    "### Moving tensor back to the CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "744bcf42",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If tensor is on GPU or MPS, can't transform it to NumPy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU or MPS, can't transform it to NumPy\n",
    "tensor_on_gpu.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7ff5d8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix the GPU tensor with NumPy issue ,we can first set it to the CPU\n",
    "\n",
    "tensor_back_to_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_to_cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
